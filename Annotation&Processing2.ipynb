{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2cf66141",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ollama\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1352280",
   "metadata": {},
   "source": [
    "# Preparing the annotation prompts & pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24d6ca1b",
   "metadata": {},
   "source": [
    "## Annotation few-shot (Abortion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9645486",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ollama import chat\n",
    "\n",
    "def classify_abortion_fewshot(text, LLM_model):\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": (\n",
    "            \"You are an expert classifier. Classify whether political speeches discuss \"\n",
    "            \"topics of abortion and/or reproductive rights (including abortion, §218, \"\n",
    "            \"reproductive autonomy, family planning, contraception, etc.), either explicitly or implicitly. \"\n",
    "            \"If yes, reply only '1'. If not, reply only '0'.\"\n",
    "        )},\n",
    "        {\"role\": \"user\", \"content\": \"Ich bin gegen die Reform des § 218. --- Are topics of abortion and reproductive rights discussed? Classify with '1' for yes or '0' for no.\"},\n",
    "        {\"role\": \"assistant\", \"content\": \"1\"},\n",
    "        {\"role\": \"user\", \"content\": \"Der Verkehrsausschuss tagte heute zum Thema Infrastruktur. --- Are topics of abortion and reproductive rights discussed? Classify with '1' for yes or '0' for no.\"},\n",
    "        {\"role\": \"assistant\", \"content\": \"0\"},\n",
    "        {\"role\": \"user\", \"content\": \"Frauen sollen selbst entscheiden dürfen, ob sie ein Kind bekommen. --- Are topics of abortion and reproductive rights discussed? Classify with '1' for yes or '0' for no.\"},\n",
    "        {\"role\": \"assistant\", \"content\": \"1\"},\n",
    "        {\"role\": \"user\", \"content\": f\"{text} --- Are topics of abortion and reproductive rights discussed? Classify with '1' for yes or '0' for no.\"}\n",
    "    ]\n",
    "    \n",
    "    response = chat(\n",
    "        model=LLM_model,\n",
    "        messages=messages,\n",
    "        options={\n",
    "            'seed': 90825,\n",
    "            'temperature': 0.1,\n",
    "            'top_p': 0.1,\n",
    "            'num_predict': 1,    \n",
    "            'num_ctx': 4096,     \n",
    "        }\n",
    "    )\n",
    "    \n",
    "    annotation_str = response['message']['content'].strip()\n",
    "    \n",
    "    if '1' in annotation_str:\n",
    "        annotation = '1'\n",
    "    elif '0' in annotation_str:\n",
    "        annotation = '0'\n",
    "    else:\n",
    "        print(f\" {annotation_str}, defaulting to '0'\")\n",
    "        annotation = '0'\n",
    "    \n",
    "    print(f\"Annotation: {annotation}\")\n",
    "    return annotation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59938277",
   "metadata": {},
   "source": [
    "## Annotation fewshot (Economy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4684265",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ollama import chat\n",
    "\n",
    "def classify_economy_fewshot(text, LLM_model):\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": (\n",
    "            \"You are an expert classifier. Classify whether political speeches discuss\"\n",
    "            \"topics of economy (including inflation, unemployment, economic growth, etc.), either explicitly or implicitly. \"\n",
    "            \"If yes, reply only '1'. If not, reply only '0'.\"\n",
    "        )},\n",
    "        {\"role\": \"user\", \"content\": \"Ohne umfassende Reformen der Bürokratie wird der Wirtschaftsstandort Deutschland leiden. --- Are topics of the economy discussed? Classify with '1' for yes or '0' for no.\"},\n",
    "        {\"role\": \"assistant\", \"content\": \"1\"},\n",
    "        {\"role\": \"user\", \"content\": \"Der Verkehrsausschuss tagte heute zum Thema Infrastruktur. --- Are topics of the economy discussed? Classify with '1' for yes or '0' for no.\"},\n",
    "        {\"role\": \"assistant\", \"content\": \"0\"},\n",
    "        {\"role\": \"user\", \"content\": \"Unser Ziel ist, dem Wirtschaftsstandort Deutschland im europäischen Vergleich dauerhaft wettbewerbsfähige Strom- und Gaspreise zu sichern. --- Are topics of the economy discussed? Classify with '1' for yes or '0' for no.\"},\n",
    "        {\"role\": \"assistant\", \"content\": \"1\"},\n",
    "        {\"role\": \"user\", \"content\": f\"{text} --- Are topics of the economy discussed? Classify with '1' for yes or '0' for no.\"}\n",
    "    ]\n",
    "    \n",
    "    response = chat(\n",
    "        model=LLM_model,\n",
    "        messages=messages,\n",
    "        options={\n",
    "            'seed': 90825,\n",
    "            'temperature': 0.1,\n",
    "            'top_p': 0.1,\n",
    "            'num_predict': 10,    \n",
    "            'num_ctx': 4096,    \n",
    "        }\n",
    "    )\n",
    "    \n",
    "    annotation_str = response['message']['content'].strip()\n",
    "    \n",
    "    if '1' in annotation_str:\n",
    "        annotation = '1'\n",
    "    elif '0' in annotation_str:\n",
    "        annotation = '0'\n",
    "    else:\n",
    "        print(f\" {annotation_str}, defaulting to '0'\")\n",
    "        annotation = '0'\n",
    "    \n",
    "    print(f\"Annotation: {annotation}\")\n",
    "    return annotation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5a457ef",
   "metadata": {},
   "source": [
    "# Collecting samples from prepared corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b01d505",
   "metadata": {},
   "source": [
    "## Selected abortion topic sample 25.04.1974"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2e5363e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Corpus_chunkified = pd.read_csv(\"./CSV/Corpus_abort_sample_chunked_annotated.csv\")\\nCorpus_chunkified = Corpus_chunkified.reset_index(drop=True)'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Corpus_chunkified = pd.read_csv(\"./CSV/Corpus_Chunkified_adjusted.csv\", index_col=0)\n",
    "Corpus_chunkified = Corpus_chunkified[Corpus_chunkified['date'] == \"[datetime.date(1974, 4, 25)]\"]\n",
    "Corpus_chunkified = Corpus_chunkified.reset_index(drop=True)\n",
    "\n",
    "#Read after initial corpus creation:\n",
    "'''Corpus_chunkified = pd.read_csv(\"./CSV/Corpus_abort_sample_chunked_annotated.csv\")\n",
    "Corpus_chunkified = Corpus_chunkified.reset_index(drop=True)'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bef5f59",
   "metadata": {},
   "source": [
    "## Selected abortion topic sample 2 - 24.06.2022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31dbecc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Corpus_chunkified = pd.read_csv(\"/home/pc/Uni/MasterThesis/Scripts/Corpus_abortion_sample2_chunked_annotated.csv\")\\nCorpus_chunkified = Corpus_chunkified.reset_index(drop=True)'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Corpus_abortion_sample2 = pd.read_csv(\"./CSV/Corpus_Chunkified_adjusted.csv\")\n",
    "Corpus_abortion_sample2 = Corpus_abortion_sample2[Corpus_abortion_sample2['date'] == \"[datetime.date(2022, 6, 24)]\"]\n",
    "Corpus_chunkified = Corpus_abortion_sample2\n",
    "Corpus_chunkified = Corpus_chunkified.reset_index(drop=True)\n",
    "\n",
    "#Read after after initial corpus creation:\n",
    "'''Corpus_chunkified = pd.read_csv(\"./CSV/Corpus_abortion_sample2_chunked_annotated.csv\")\n",
    "Corpus_chunkified = Corpus_chunkified.reset_index(drop=True)'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1842e96c",
   "metadata": {},
   "source": [
    "## Generating random sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93c40c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Corpus_econ_sample = pd.read_csv(\"./CSV/CorpusChunked_adjusted.csv\")\n",
    "Corpus_econ_sample = Corpus_econ_sample.sample(n=150, random_state=42).reset_index(drop=True)\n",
    "Corpus_chunkified = Corpus_econ_sample\n",
    "\n",
    "\n",
    "#Read after after initial corpus creation:\n",
    "'''Corpus_chunkified = pd.read_csv(\"./CSV/Corpus_econ_sample_chunked_annotated.csv\")\n",
    "Corpus_chunkified = Corpus_chunkified.reset_index(drop=True)'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1b4e74f",
   "metadata": {},
   "source": [
    "## Generating sample 2 (diachronic approach)\n",
    "For the diachronic comparison a second random sample, sampled after 2020 is drawn to contrast against the comparison of the abortion annotation task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afb01ced",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_year(date_str):\n",
    "\timport re\n",
    "\tmatch = re.search(r'(\\d{4})', str(date_str))\n",
    "\tif match:\n",
    "\t\treturn int(match.group(1))\n",
    "\treturn None\n",
    "\n",
    "Corpus_econ_sample2 = pd.read_csv(\"./CSV/CorpusChunked_adjusted.csv\")\n",
    "\n",
    "Corpus_econ_sample2['year'] = Corpus_econ_sample2['date'].apply(extract_year)\n",
    "Corpus_econ_sample2 = Corpus_econ_sample2[Corpus_econ_sample2['year'] >= 2020]\n",
    "Corpus_chunkified = Corpus_econ_sample2.sample(n=150, random_state=42).reset_index(drop=True)\n",
    "\n",
    "Corpus_chunkified = pd.read_csv(\"./CSV/Corpus_econ_sample_chunked_annotated.csv\")\n",
    "Corpus_chunkified = Corpus_chunkified[0:150]\n",
    "print(f\"Corpus_chunkified loaded with {len(Corpus_chunkified)} entries.\")\n",
    "print(Corpus_chunkified.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06232db5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['phi:2.7b', 'phi:latest', 'gemma3:4b', 'gpt-oss:20b', 'qwen2.5:7b', 'mistral:7b', 'stablelm2:12b', 'localmind/sauerkrautlm:latest', 'dolphin-mixtral:latest', 'llama3.2:latest', 'hf.co/TheBloke/SOLAR-10.7B-Instruct-v1.0-uncensored-GGUF:Q2_K', 'deepseek-r1:8b', 'huihui_ai/deepseek-r1-abliterated:latest', 'huihui_ai/deepseek-r1-abliterated:8b']\n"
     ]
    }
   ],
   "source": [
    "#Check if the models are correctly loaded\n",
    "'''models = ollama.list()\n",
    "print([model['model'] for model in models['models']])\n",
    "del models'''\n",
    "#Create the metrics dataframe for model speed comparison\n",
    "Model_metrics_df = pd.DataFrame(columns=['Model', 'Speed', 'Time_taken'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2fa0c8b",
   "metadata": {},
   "source": [
    "# Model tester pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59a6d4e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def annotator(model, Corpus_df, Model_metrics_df, start_index=0, end_index=None, batch_size=100, output_file=\"./CSV/corpus_chunks.csv\", topic = \"Abortion\"):\n",
    "    \n",
    "    start_time = time.time() #This variable measures the start of the annotation process based on system time. \n",
    "    \n",
    "    if end_index is None:\n",
    "        end_index = len(Corpus_df)\n",
    "    for batch_start in range(start_index, end_index, batch_size):\n",
    "        batch_end = min(batch_start + batch_size, end_index)\n",
    "        for idx in range(batch_start, batch_end):\n",
    "            try:\n",
    "                chunk = Corpus_df.loc[Corpus_df.index == idx, \"chunk\"].values[0]\n",
    "                if topic == \"Abortion\":\n",
    "                    annotation = classify_abortion_fewshot(chunk, model)\n",
    "                elif topic == \"Economy\":\n",
    "                    annotation = classify_economy_fewshot(chunk, model)\n",
    "                else:\n",
    "                    annotation = None\n",
    "                    print(f\"Unknown topic: {topic}\")\n",
    "                Corpus_df.loc[Corpus_df.index == idx, model] = annotation\n",
    "                time.sleep(1)\n",
    "            except Exception as e:\n",
    "                print(f\"Error annotating chunk at index {idx}: {e}\")\n",
    "                Corpus_df.loc[Corpus_df.index == idx, model] = None\n",
    "                time.sleep(1)\n",
    "        # Save after each batch\n",
    "        Corpus_df.to_csv(output_file, index=False)\n",
    "        print(f\"Saved batch {batch_start}-{batch_end} to {output_file}\")\n",
    "        \n",
    "    end_time = time.time() # Capturing end time based on system time\n",
    "    elapsed_time = end_time - start_time # Calculating elapsed time for the entire annotation per sample for each model. \n",
    "    print(f\"Elapsed time for annotation: {elapsed_time:.2f} seconds\")    \n",
    "    model_speed = len(Corpus_df) / elapsed_time\n",
    "    Model_metrics_df.loc[len(Model_metrics_df)] = {'Model': model, 'Speed': model_speed, 'Time_taken': elapsed_time}\n",
    "    print(Model_metrics_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb02025a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_list = [\"phi:2.7b\", \"gemma3:4b\", \"qwen2.5:7b\", \"mistral:7b\", \"stablelm2:12b\",\"llama3.2:latest\"]\n",
    "\n",
    "for model in model_list:\n",
    "    annotator(model, Corpus_chunkified, start_index=0, topic=\"Abortion\", Model_metrics_df=Model_metrics_df) \n",
    "    Corpus_chunkified_annotated = Corpus_chunkified.copy()\n",
    "Corpus_chunkified_annotated.to_csv(\"./CSV/Corpus_abortion_sample3_chunked_annotated.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6b32b69",
   "metadata": {},
   "source": [
    "## Finishing touches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a0dd097",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(Model_metrics_df)):\n",
    "    Model_metrics_df['Time_per_annotation'] = Model_metrics_df['Time_taken'] / 150 # Calculates the mean time per individual annotation \n",
    "\n",
    "Corpus_df_annotated_cleaned = Corpus_chunkified.copy()\n",
    "\n",
    "def cleanup(model, Corpus_df):\n",
    "    \n",
    "    if Corpus_df[model].dtype != int:\n",
    "        Corpus_df_annotated_cleaned[model] = Corpus_df[model].astype(str)\n",
    "        Corpus_df_annotated_cleaned[model] = Corpus_df_annotated_cleaned[model].apply(lambda x: '1' if '1' in x else ('0' if '0' in x else None))\n",
    "        if Corpus_df_annotated_cleaned[model].isnull().any():\n",
    "            Corpus_df_annotated_cleaned[model] = Corpus_df_annotated_cleaned[model].fillna(0)\n",
    "            Corpus_df_annotated_cleaned[model] = Corpus_df_annotated_cleaned[model].astype(int)\n",
    "    return Corpus_df_annotated_cleaned\n",
    "\n",
    "# Cleaning up all model columns for enabling the calculation of evaluation metrics. SciLearn prefers integer values.\n",
    "\n",
    "for model_name in Corpus_chunkified.columns[5:]: #The first five columns are metadata, the later columns are annotations\n",
    "    Corpus_df_annotated_cleaned = cleanup(model_name, Corpus_chunkified)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6b601d7",
   "metadata": {},
   "source": [
    "## Saving the results after each task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59550a75",
   "metadata": {},
   "outputs": [],
   "source": [
    "Model_metrics_df.to_csv(\"./CSV/Model_metrics_econ_sample2.csv\", index=False)\n",
    "Corpus_df_annotated_cleaned.to_csv(\"./CSV/Corpus_Chunked_annotated_cleaned.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e644c076",
   "metadata": {},
   "source": [
    "# For the final corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14d2d1f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "Corpus_chunkified_adjusted_full = annotator(\"qwen2.5:7b\", Corpus_chunkified, start_index=0, topic=\"Abortion\", Model_metrics_df=Model_metrics_df) \n",
    "Corpus_chunkified_adjusted_clean = cleanup(\"qwen2.5:7b\", Corpus_chunkified_adjusted_full)\n",
    "Corpus_chunkified_adjusted_clean.to_csv(\"./CSV/Corpus_Chunkified_adjusted_full.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
