               Model                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             Scores
0  Student assistent                                {'0': {'precision': 0.9313725490196079, 'recall': 1.0, 'f1-score': 0.9644670050761421, 'support': 95.0}, '1': {'precision': 1.0, 'recall': 0.8970588235294118, 'f1-score': 0.9457364341085271, 'support': 68.0}, 'accuracy': 0.9570552147239264, 'macro avg': {'precision': 0.9656862745098039, 'recall': 0.9485294117647058, 'f1-score': 0.9551017195923346, 'support': 163.0}, 'weighted avg': {'precision': 0.9600024058703237, 'recall': 0.9570552147239264, 'f1-score': 0.9566530245497751, 'support': 163.0}}
1         qwen2.5:7b              {'0': {'precision': 0.9278350515463918, 'recall': 0.9473684210526315, 'f1-score': 0.9375, 'support': 95.0}, '1': {'precision': 0.9242424242424242, 'recall': 0.8970588235294118, 'f1-score': 0.9104477611940298, 'support': 68.0}, 'accuracy': 0.9263803680981595, 'macro avg': {'precision': 0.9260387378944079, 'recall': 0.9222136222910217, 'f1-score': 0.9239738805970149, 'support': 163.0}, 'weighted avg': {'precision': 0.9263362867815466, 'recall': 0.9263803680981595, 'f1-score': 0.9262144034429082, 'support': 163.0}}
2          gemma3:4b  {'0': {'precision': 0.9878048780487805, 'recall': 0.8526315789473684, 'f1-score': 0.9152542372881356, 'support': 95.0}, '1': {'precision': 0.8271604938271605, 'recall': 0.9852941176470589, 'f1-score': 0.8993288590604027, 'support': 68.0}, 'accuracy': 0.9079754601226994, 'macro avg': {'precision': 0.9074826859379705, 'recall': 0.9189628482972136, 'f1-score': 0.9072915481742692, 'support': 163.0}, 'weighted avg': {'precision': 0.9207875889256507, 'recall': 0.9079754601226994, 'f1-score': 0.9086105212176704, 'support': 163.0}}
3         mistral:7b   {'0': {'precision': 0.9770114942528736, 'recall': 0.8947368421052632, 'f1-score': 0.9340659340659341, 'support': 95.0}, '1': {'precision': 0.868421052631579, 'recall': 0.9705882352941176, 'f1-score': 0.9166666666666666, 'support': 68.0}, 'accuracy': 0.9263803680981595, 'macro avg': {'precision': 0.9227162734422263, 'recall': 0.9326625386996904, 'f1-score': 0.9253663003663004, 'support': 163.0}, 'weighted avg': {'precision': 0.9317099603249716, 'recall': 0.9263803680981595, 'f1-score': 0.9268073439852582, 'support': 163.0}}
4    llama3.2:latest  {'0': {'precision': 0.9368421052631579, 'recall': 0.9368421052631579, 'f1-score': 0.9368421052631579, 'support': 95.0}, '1': {'precision': 0.9117647058823529, 'recall': 0.9117647058823529, 'f1-score': 0.9117647058823529, 'support': 68.0}, 'accuracy': 0.9263803680981595, 'macro avg': {'precision': 0.9243034055727555, 'recall': 0.9243034055727555, 'f1-score': 0.9243034055727555, 'support': 163.0}, 'weighted avg': {'precision': 0.9263803680981595, 'recall': 0.9263803680981595, 'f1-score': 0.9263803680981595, 'support': 163.0}}
5      stablelm2:12b    {'0': {'precision': 0.9775280898876404, 'recall': 0.9157894736842105, 'f1-score': 0.9456521739130435, 'support': 95.0}, '1': {'precision': 0.8918918918918919, 'recall': 0.9705882352941176, 'f1-score': 0.9295774647887324, 'support': 68.0}, 'accuracy': 0.9386503067484663, 'macro avg': {'precision': 0.9347099908897661, 'recall': 0.943188854489164, 'f1-score': 0.937614819350888, 'support': 163.0}, 'weighted avg': {'precision': 0.9418025594354263, 'recall': 0.9386503067484663, 'f1-score': 0.9389461602906314, 'support': 163.0}}
6           phi:2.7b   {'0': {'precision': 0.7604166666666666, 'recall': 0.7684210526315789, 'f1-score': 0.7643979057591623, 'support': 95.0}, '1': {'precision': 0.6716417910447762, 'recall': 0.6617647058823529, 'f1-score': 0.6666666666666666, 'support': 68.0}, 'accuracy': 0.7239263803680982, 'macro avg': {'precision': 0.7160292288557214, 'recall': 0.715092879256966, 'f1-score': 0.7155322862129145, 'support': 163.0}, 'weighted avg': {'precision': 0.7233817492293135, 'recall': 0.7239263803680982, 'f1-score': 0.7236265912911273, 'support': 163.0}}